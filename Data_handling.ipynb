{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8804eb5f",
   "metadata": {},
   "source": [
    "# **Data Handling and Preprocessing**  \n",
    "## **Professional Air Pollution Data Processing Notebook**  \n",
    "*This notebook focuses on comprehensive preprocessing of air pollution time-series data. The goal is to clean, structure, and transform raw data into a format suitable for forecasting and analysis.*  \n",
    "ðŸ“Œ **Objectives of this Notebook:**  \n",
    "- Load, inspect, and preprocess raw data.  \n",
    "- Handle missing values and inconsistencies.  \n",
    "- Create engineered features to enhance forecasting models.  \n",
    "- Save the final processed dataset for modeling and visualization.  \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef48a7a",
   "metadata": {},
   "source": [
    "## **Step 1: Import Required Libraries**  \n",
    "To efficiently manage and preprocess air pollution data, we import key Python libraries:  \n",
    "- **`pandas`**: For data manipulation and handling.  \n",
    "- **`matplotlib.pyplot`**: For visualization (if needed later).  \n",
    "Ensuring the correct version of pandas is used for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure consistent pandas version\n",
    "print(f\"Using pandas version: {pd.__version__}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46917f7b",
   "metadata": {},
   "source": [
    "## **Step 2: Load the Raw Dataset**  \n",
    "The dataset, stored in CSV format, is loaded into a Pandas DataFrame.  \n",
    "**Key actions in this step:**  \n",
    "- Read the file and store it as `raw_data`.  \n",
    "- Display the first and last few rows for initial inspection.  \n",
    "- Identify potential missing values and inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loaded raw dataset\n",
      "    Timestamp  PM2.5 (Âµg/mÂ³)  PM10 (Âµg/mÂ³)  NO (Âµg/mÂ³)  NO2 (Âµg/mÂ³)  \\\n",
      "0  01-01-2017          230.5        329.45       14.22        11.21   \n",
      "1  02-01-2017            NaN           NaN         NaN          NaN   \n",
      "2  03-01-2017            NaN           NaN         NaN          NaN   \n",
      "\n",
      "   NOx (ppb)  NH3 (Âµg/mÂ³)  SO2 (Âµg/mÂ³)  CO (mg/mÂ³)  Ozone (Âµg/mÂ³)  ...  \\\n",
      "0      25.43          NaN          NaN        0.74           56.5  ...   \n",
      "1        NaN          NaN          NaN         NaN            NaN  ...   \n",
      "2        NaN          NaN          NaN         NaN            NaN  ...   \n",
      "\n",
      "   AT (Â°C)  RH (%)  WS (m/s)  WD (deg)  RF (mm)  TOT-RF (mm)  SR (W/mt2)  \\\n",
      "0      NaN     NaN       NaN       NaN      NaN          0.0         NaN   \n",
      "1      NaN     NaN       NaN       NaN      NaN          0.0         NaN   \n",
      "2      NaN     NaN       NaN       NaN      NaN          0.0         NaN   \n",
      "\n",
      "   BP (mmHg)  VWS (m/s)  Station_ID  \n",
      "0        NaN        NaN           1  \n",
      "1        NaN        NaN           1  \n",
      "2        NaN        NaN           1  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "        Timestamp  PM2.5 (Âµg/mÂ³)  PM10 (Âµg/mÂ³)  NO (Âµg/mÂ³)  NO2 (Âµg/mÂ³)  \\\n",
      "94569  29-12-2023     207.166667    271.750000    4.458333    41.803125   \n",
      "94570  30-12-2023     180.791667    240.958333    2.661458    32.281250   \n",
      "94571  31-12-2023     149.399306    200.062500    2.550694    27.543750   \n",
      "\n",
      "       NOx (ppb)  NH3 (Âµg/mÂ³)  SO2 (Âµg/mÂ³)  CO (mg/mÂ³)  Ozone (Âµg/mÂ³)  ...  \\\n",
      "94569  25.872917    46.450000     7.014931    1.639931      18.278125  ...   \n",
      "94570  19.342708    38.886458     6.905903    1.446528      24.798958  ...   \n",
      "94571  16.740625    31.838194     6.118403    1.245486      24.326042  ...   \n",
      "\n",
      "        AT (Â°C)     RH (%)  WS (m/s)    WD (deg)  RF (mm)  TOT-RF (mm)  \\\n",
      "94569  8.215625  85.273958       NaN   93.727083      0.0          0.0   \n",
      "94570  8.261458  81.335417       NaN  107.293750      0.0          0.0   \n",
      "94571  8.200000  78.748264       NaN   75.870833      0.0          0.0   \n",
      "\n",
      "       SR (W/mt2)   BP (mmHg)  VWS (m/s)  Station_ID  \n",
      "94569   32.033333  973.986458        NaN          37  \n",
      "94570   29.584375  973.867708        NaN          37  \n",
      "94571   21.415972  973.800000        NaN          37  \n",
      "\n",
      "[3 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the raw dataset\n",
    "file_path = \"all_stations_daily_data.csv\"\n",
    "raw_data = pd.read_csv(file_path)\n",
    "print(\"Step 1: Loaded raw dataset\")\n",
    "print(raw_data.head(3))\n",
    "print(raw_data.tail(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56072835",
   "metadata": {},
   "source": [
    "## **Step 3: Convert 'Timestamp' to Datetime Format**  \n",
    "The dataset contains a column named 'Timestamp' in string format.  \n",
    "To perform time-series operations, we convert it to a `datetime` object.  \n",
    "**Why is this necessary?**  \n",
    "- Ensures proper handling of time-dependent trends.  \n",
    "- Enables feature engineering (such as extracting year, month, and day).  \n",
    "- Facilitates smooth visualization and forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Converted 'Timestamp' to datetime\n",
      "   Timestamp\n",
      "0 2017-01-01\n",
      "1 2017-01-02\n",
      "2 2017-01-03\n",
      "3 2017-01-04\n",
      "4 2017-01-05\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert 'Timestamp' to datetime for feature engineering\n",
    "raw_data['Timestamp'] = pd.to_datetime(raw_data['Timestamp'], dayfirst=True, errors='coerce')\n",
    "print(\"\\nStep 2: Converted 'Timestamp' to datetime\")\n",
    "print(raw_data[['Timestamp']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e174ee",
   "metadata": {},
   "source": [
    "## **Step 4: Generate Time-based Features**  \n",
    "To enhance forecasting accuracy, we extract multiple time-based features:  \n",
    "- **Year**: Extracts the year from the timestamp.  \n",
    "- **Month**: Extracts the month of the year.  \n",
    "- **Day**: Extracts the day of the month.  \n",
    "- **DayOfWeek**: Identifies the weekday (0=Monday, 6=Sunday).  \n",
    "These features provide valuable insights for trend analysis and seasonality detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Added time-based features\n",
      "   Year  Month  Day  DayOfWeek\n",
      "0  2017      1    1          6\n",
      "1  2017      1    2          0\n",
      "2  2017      1    3          1\n",
      "3  2017      1    4          2\n",
      "4  2017      1    5          3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Add time-based features\n",
    "raw_data['Year'] = raw_data['Timestamp'].dt.year\n",
    "raw_data['Month'] = raw_data['Timestamp'].dt.month\n",
    "raw_data['Day'] = raw_data['Timestamp'].dt.day\n",
    "raw_data['DayOfWeek'] = raw_data['Timestamp'].dt.dayofweek\n",
    "print(\"\\nStep 3: Added time-based features\")\n",
    "print(raw_data[['Year', 'Month', 'Day', 'DayOfWeek']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf262f81",
   "metadata": {},
   "source": [
    "## **Step 5: Define Core Features for Processing**  \n",
    "Certain pollutants are crucial indicators of air quality. We focus on the following:  \n",
    "- **PM2.5 (Âµg/mÂ³)**: Fine particulate matter.  \n",
    "- **PM10 (Âµg/mÂ³)**: Coarse particulate matter.  \n",
    "- **NOx (ppb)**: Nitrogen oxides concentration.  \n",
    "- **CO (mg/mÂ³)**: Carbon monoxide concentration.  \n",
    "- **Ozone (Âµg/mÂ³)**: Ground-level ozone levels.  \n",
    "These pollutants are critical for understanding pollution trends and forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Defined core features for processing\n",
      "['PM2.5 (Âµg/mÂ³)', 'PM10 (Âµg/mÂ³)', 'NOx (ppb)', 'CO (mg/mÂ³)', 'Ozone (Âµg/mÂ³)']\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Define core features for processing\n",
    "core_features = ['PM2.5 (Âµg/mÂ³)', 'PM10 (Âµg/mÂ³)', 'NOx (ppb)', 'CO (mg/mÂ³)', 'Ozone (Âµg/mÂ³)']\n",
    "print(\"\\nStep 4: Defined core features for processing\")\n",
    "print(core_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a23da3",
   "metadata": {},
   "source": [
    "## **Step 6: Interpolate Missing Values**  \n",
    "Handling missing data is essential to ensure dataset integrity.  \n",
    "**Approach used:**  \n",
    "- **Linear Interpolation:** Missing values are estimated based on neighboring values within the same station group.  \n",
    "- **Explicit Rounding:** Values are rounded to four decimal places to maintain consistency.  \n",
    "This step prevents data gaps from affecting forecasting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Interpolate missing values with explicit rounding\n",
    "for feature in core_features:\n",
    "    if feature in raw_data.columns:\n",
    "        interpolated_data = (\n",
    "            raw_data.reset_index()  # Reset index\n",
    "            .groupby('Station_ID')[feature]\n",
    "            .apply(lambda x: x.interpolate(method='linear', limit_direction='both'))\n",
    "        )\n",
    "        raw_data[feature] = interpolated_data.values  # Align values directly\n",
    "        raw_data[feature] = raw_data[feature].round(4)  # Explicit rounding to 4 decimal places\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce72ce6",
   "metadata": {},
   "source": [
    "## **Step 7: Create Rolling Averages and Lag Features**  \n",
    "To capture temporal dependencies, we introduce additional statistical features:  \n",
    "- **7-day rolling mean**: Computes the average of pollutant levels over the past week.  \n",
    "- **Lag features**: Stores the previous day's pollutant values as an independent feature.  \n",
    "These transformations help in time-series forecasting by identifying trends and variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6: Created rolling averages and lag features\n",
      "   PM2.5 (Âµg/mÂ³)_rolling_mean  PM10 (Âµg/mÂ³)_rolling_mean  \\\n",
      "0                    230.5000                   329.4500   \n",
      "1                    230.0676                   328.8471   \n",
      "2                    229.6352                   328.2442   \n",
      "3                    229.2028                   327.6412   \n",
      "4                    228.7705                   327.0383   \n",
      "\n",
      "   NOx (ppb)_rolling_mean  CO (mg/mÂ³)_rolling_mean  Ozone (Âµg/mÂ³)_rolling_mean  \n",
      "0                 25.4300                   0.7400                     56.5000  \n",
      "1                 25.4745                   0.7410                     56.4408  \n",
      "2                 25.5190                   0.7421                     56.3816  \n",
      "3                 25.5636                   0.7431                     56.3224  \n",
      "4                 25.6081                   0.7441                     56.2632  \n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create rolling averages and lag features for pollutants\n",
    "for feature in core_features:\n",
    "    if feature in raw_data.columns:\n",
    "        # Rolling mean\n",
    "        raw_data[f'{feature}_rolling_mean'] = raw_data.groupby(\"Station_ID\")[feature].transform(\n",
    "            lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    "        ).round(4)  # Explicit rounding to 4 decimal places\n",
    "        # Lag feature\n",
    "        raw_data[f'{feature}_lag_1'] = raw_data.groupby(\"Station_ID\")[feature].shift(1).round(4)\n",
    "print(\"\\nStep 6: Created rolling averages and lag features\")\n",
    "print(raw_data[[f'{feature}_rolling_mean' for feature in core_features]].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44f68e",
   "metadata": {},
   "source": [
    "## **Step 8: Handle NaNs in Derived Features**  \n",
    "Some newly created features may contain missing values. To address this, we use:  \n",
    "- **Backward-fill (`bfill`) method**: Fills NaNs by propagating values backward.  \n",
    "- **Explicit rounding**: Ensures numerical stability for models.  \n",
    "This step ensures that no NaN values remain in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 7: Handled NaNs in derived features\n",
      "   PM2.5 (Âµg/mÂ³)_lag_1  PM10 (Âµg/mÂ³)_lag_1  NOx (ppb)_lag_1  CO (mg/mÂ³)_lag_1  \\\n",
      "0             230.5000            329.4500          25.4300            0.7400   \n",
      "1             230.5000            329.4500          25.4300            0.7400   \n",
      "2             229.6352            328.2442          25.5190            0.7421   \n",
      "3             228.7705            327.0383          25.6081            0.7441   \n",
      "4             227.9057            325.8325          25.6971            0.7462   \n",
      "\n",
      "   Ozone (Âµg/mÂ³)_lag_1  \n",
      "0              56.5000  \n",
      "1              56.5000  \n",
      "2              56.3816  \n",
      "3              56.2632  \n",
      "4              56.1449  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_33324\\1856277772.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  raw_data[f'{feature}_lag_1'] = raw_data[f'{feature}_lag_1'].fillna(method='bfill').round(4)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_33324\\1856277772.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  raw_data[f'{feature}_rolling_mean'] = raw_data[f'{feature}_rolling_mean'].fillna(method='bfill').round(4)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Handle NaNs in derived features with rounding\n",
    "for feature in core_features:\n",
    "    if feature in raw_data.columns:\n",
    "        raw_data[f'{feature}_lag_1'] = raw_data[f'{feature}_lag_1'].fillna(method='bfill').round(4)\n",
    "        raw_data[f'{feature}_rolling_mean'] = raw_data[f'{feature}_rolling_mean'].fillna(method='bfill').round(4)\n",
    "print(\"\\nStep 7: Handled NaNs in derived features\")\n",
    "print(raw_data[[f'{feature}_lag_1' for feature in core_features]].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977f65f8",
   "metadata": {},
   "source": [
    "## **Step 9: Forward-Fill Any Remaining Missing Data**  \n",
    "To ensure data continuity, any remaining missing values are forward-filled (`ffill`).  \n",
    "**Key benefits:**  \n",
    "- Ensures time-series consistency.  \n",
    "- Avoids data gaps affecting model predictions.  \n",
    "- Preserves historical trends in pollution levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8: Forward-filled remaining NaNs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_33324\\2063416860.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  raw_data = raw_data.fillna(method='ffill').round(4)\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Forward-fill any remaining NaNs\n",
    "raw_data = raw_data.fillna(method='ffill').round(4)\n",
    "print(\"\\nStep 8: Forward-filled remaining NaNs\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 9: Enhanced dataset saved to: Enhanced_Time-Series_Air_Pollution_Data_Revised.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Save the enhanced dataset to a new file with rounding applied\n",
    "output_path = \"Enhanced_Time-Series_Air_Pollution_Data_Revised.csv\"\n",
    "cleaned_data = raw_data.reset_index(drop=True).round(4)\n",
    "cleaned_data.to_csv(output_path, index=False)\n",
    "print(f\"\\nStep 9: Enhanced dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81f61e",
   "metadata": {},
   "source": [
    "## Step 10: Save the Enhanced Dataset\n",
    "\n",
    "After processing, we save the cleaned dataset into a new CSV file for further analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c1506",
   "metadata": {},
   "source": [
    "## **Step 10: Save the Enhanced Dataset**  \n",
    "Once the data is fully processed, we save it to a new CSV file.  \n",
    "**Filename:** `Enhanced_Time-Series_Air_Pollution_Data_Revised.csv`  \n",
    "This cleaned dataset is now ready for advanced modeling, forecasting, and visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
